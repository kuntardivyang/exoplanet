# ğŸš€ Exoplanet Detection System

AI-powered exoplanet detection and classification system built for NASA Space Apps Challenge 2025.

## ğŸŒŸ Features

- **Multiple ML Models**: Random Forest, XGBoost, LightGBM, Neural Networks, Gradient Boosting
- **Three NASA Datasets**: Kepler, TESS, and K2 missions
- **Complete Pipeline**: Data preprocessing, feature engineering, model training, and evaluation
- **Web Interface**: Interactive React-based UI for predictions and model management
- **RESTful API**: FastAPI backend with comprehensive endpoints
- **Real-time Training**: Monitor model training progress in real-time
- **Batch Predictions**: Support for CSV upload and batch processing
- **Feature Importance**: Visualize which features matter most for detection

## ğŸ“ Project Structure

```
exoplanet/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/                    # FastAPI endpoints
â”‚   â”‚   â”œâ”€â”€ main.py            # Main API application
â”‚   â”‚   â””â”€â”€ schemas.py         # Pydantic models
â”‚   â”œâ”€â”€ models/                # ML models
â”‚   â”‚   â”œâ”€â”€ train_pipeline.py  # Training pipeline
â”‚   â”‚   â”œâ”€â”€ model_trainer.py   # Model training logic
â”‚   â”‚   â””â”€â”€ predictor.py       # Prediction service
â”‚   â”œâ”€â”€ utils/                 # Utilities
â”‚   â”‚   â”œâ”€â”€ data_loader.py     # Dataset loading
â”‚   â”‚   â”œâ”€â”€ preprocessing.py   # Data preprocessing
â”‚   â”‚   â”œâ”€â”€ data_exploration.py # Data analysis
â”‚   â”‚   â””â”€â”€ logger.py          # Logging utilities
â”‚   â””â”€â”€ config/                # Configuration
â”‚       â””â”€â”€ config.py          # Settings
â”œâ”€â”€ frontend/                  # React application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/            # UI pages
â”‚   â”‚   â”œâ”€â”€ components/       # React components
â”‚   â”‚   â”œâ”€â”€ services/         # API services
â”‚   â”‚   â””â”€â”€ styles/           # CSS styles
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Raw CSV datasets
â”‚   â”œâ”€â”€ processed/            # Processed data
â”‚   â””â”€â”€ models/               # Saved models
â”œâ”€â”€ notebooks/                # Jupyter notebooks
â””â”€â”€ logs/                     # Application logs
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Node.js 18+
- pip
- npm or yarn

### Backend Setup

1. **Create virtual environment**:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. **Install dependencies**:
```bash
pip install -r requirements.txt
```

3. **Train your first model**:
```bash
cd backend/models
python train_pipeline.py
```

This will:
- Load the Kepler dataset
- Preprocess and clean the data
- Train 5 different ML models
- Evaluate and save the best model
- Generate comparison reports

4. **Start the API server**:
```bash
cd backend/api
python main.py
```

API will be available at `http://localhost:8000`
- Docs: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

### Frontend Setup

1. **Install dependencies**:
```bash
cd frontend
npm install
```

2. **Start development server**:
```bash
npm run dev
```

Frontend will be available at `http://localhost:3000`

## ğŸ¯ Usage

### 1. Dashboard
- View system status and model performance
- Explore dataset statistics
- See feature importance charts

### 2. Make Predictions
- **Single Prediction**: Enter feature values manually
- **Batch Prediction**: Add multiple samples
- **CSV Upload**: Upload a CSV file for bulk predictions

### 3. Train Models
- Select dataset (Kepler, TESS, or K2)
- Start training process
- Monitor real-time progress
- View training results and metrics

### 4. Data Explorer
- Browse available datasets
- View sample data
- Explore feature distributions

### 5. Model Management
- View all trained models
- Compare model performance
- Load different models
- View feature importance

## ğŸ”§ API Endpoints

### Health & Status
- `GET /health` - API health check
- `GET /` - Root endpoint

### Predictions
- `POST /predict` - Single prediction
- `POST /predict/batch` - Batch predictions
- `POST /predict/upload` - CSV file upload

### Models
- `GET /models` - List all models
- `GET /models/{name}/info` - Model details
- `POST /models/load/{name}` - Load specific model

### Training
- `POST /train` - Start training
- `GET /train/status` - Training status

### Features & Data
- `GET /features/importance` - Feature importance
- `GET /datasets` - List datasets
- `GET /datasets/{name}/sample` - Dataset sample

## ğŸ“Š Datasets

### Kepler (KOI)
- **Samples**: ~9,500
- **Features**: 141 columns
- **Classes**: CONFIRMED, FALSE POSITIVE, CANDIDATE

### TESS (TOI)
- **Samples**: ~7,800
- **Features**: Multiple transit and stellar parameters

### K2
- **Samples**: ~4,300
- **Features**: Planet and candidate data

## ğŸ¤– ML Models

### Random Forest
- Ensemble of decision trees
- Robust to overfitting
- Good baseline performance

### XGBoost
- Gradient boosting framework
- High accuracy with proper tuning
- Handles missing data well

### LightGBM
- Fast training on large datasets
- Memory efficient
- Excellent for high-dimensional data

### Neural Network
- Multi-layer perceptron
- Captures complex patterns
- Requires sufficient training data

### Gradient Boosting
- Sequential ensemble method
- Good generalization
- Handles various data types

## ğŸ“ˆ Performance Metrics

Models are evaluated using:
- **Accuracy**: Overall correctness
- **Precision**: True positive rate
- **Recall**: Sensitivity
- **F1 Score**: Harmonic mean of precision and recall
- **ROC AUC**: Area under ROC curve
- **Confusion Matrix**: Detailed classification results

## ğŸ”¬ Technical Details

### Data Preprocessing
1. **Cleaning**: Remove duplicates, handle missing values
2. **Feature Selection**: Correlation analysis, top-k selection
3. **Scaling**: StandardScaler or RobustScaler
4. **Outlier Handling**: IQR-based clipping
5. **Train/Val/Test Split**: 70/10/20

### Feature Engineering
- Automatic feature selection based on correlation
- Missing value imputation (median/mean/KNN)
- Outlier detection and handling
- Feature importance ranking

## ğŸ¨ Frontend Technology

- **React 18**: Modern UI framework
- **Tailwind CSS**: Utility-first styling
- **Recharts**: Data visualization
- **Axios**: API communication
- **React Router**: Navigation
- **Lucide Icons**: Beautiful icons

## ğŸ” Security

- CORS protection
- Input validation with Pydantic
- Error handling and logging
- Rate limiting ready

## ğŸš€ Deployment

### Backend (Production)
```bash
uvicorn backend.api.main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Frontend (Production)
```bash
npm run build
# Serve the dist/ folder with your preferred web server
```

## ğŸ“ License

This project is built for NASA Space Apps Challenge 2025.

## ğŸ¤ Contributing

This is a challenge submission. For NASA Space Apps Challenge participants only.

## ğŸ“§ Support

For issues and questions, please refer to the challenge documentation.

## ğŸŒŸ Acknowledgments

- NASA Exoplanet Archive for datasets
- Kepler, TESS, and K2 missions
- NASA Space Apps Challenge organizers
- Open-source ML community

---

**Built with â¤ï¸ for exoplanet discovery and the search for life beyond Earth**
