# ğŸŒŸ Exoplanet Detection System - Complete Overview

## NASA Space Apps Challenge 2025
**Challenge**: A World Away - Hunting for Exoplanets with AI

---

## ğŸ¯ Project Summary

A complete end-to-end AI-powered system for detecting and classifying exoplanets from NASA's open-source datasets. The system features:

- **5 Machine Learning Models** trained in parallel
- **3 NASA Datasets** (Kepler, TESS, K2)
- **Full-stack Web Application** with React + FastAPI
- **Real-time Training Monitoring**
- **Batch Prediction Support**
- **Interactive Visualizations**

---

## ğŸ“Š System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Frontend (React)                        â”‚
â”‚  Dashboard | Predictions | Training | Data Explorer | Models â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ HTTP/REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Backend (FastAPI)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  API Endpoints                                        â”‚  â”‚
â”‚  â”‚  /predict | /train | /models | /datasets | /features â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                         â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ML Pipeline                                          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚
â”‚  â”‚  â”‚ Data Loaderâ”‚â”€â–¶â”‚Preprocessorâ”‚â”€â–¶â”‚  Trainer   â”‚     â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Layer                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Kepler (9.5k)â”‚  â”‚  TESS (7.8k) â”‚  â”‚   K2 (4.3k)  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  Machine Learning Pipeline

### 1. Data Loading & Exploration
- **DatasetLoader**: Loads CSV files from NASA Exoplanet Archive
- **DataExplorer**: Analyzes distributions, correlations, outliers
- Handles 3 datasets: Kepler KOI, TESS TOI, K2 Planets

### 2. Preprocessing Pipeline
**ExoplanetPreprocessor** performs:
- âœ… Data cleaning (duplicates, constants)
- âœ… Missing value imputation (median/mean/KNN)
- âœ… Outlier detection and handling (IQR method)
- âœ… Feature selection (correlation-based)
- âœ… Feature scaling (Standard/Robust scaler)
- âœ… Train/Validation/Test split (70/10/20)

### 3. Model Training
**ExoplanetModelTrainer** trains 5 models:

| Model | Description | Strengths |
|-------|-------------|-----------|
| **Random Forest** | Ensemble of decision trees | Robust, interpretable |
| **XGBoost** | Gradient boosting | High accuracy, handles missing data |
| **LightGBM** | Fast gradient boosting | Efficient, memory-friendly |
| **Neural Network** | Multi-layer perceptron | Complex patterns |
| **Gradient Boosting** | Sequential ensemble | Good generalization |

### 4. Evaluation Metrics
Each model is evaluated on:
- **Accuracy**: Overall correctness
- **Precision**: True positive rate
- **Recall**: Sensitivity
- **F1 Score**: Harmonic mean
- **ROC AUC**: Discrimination ability
- **Confusion Matrix**: Detailed breakdown

---

## ğŸ¨ Frontend Features

### Dashboard
- System health monitoring
- Dataset statistics
- Feature importance visualization
- Target distribution charts
- Quick action cards

### Predictions
- **Single Prediction**: Manual feature input
- **Batch Prediction**: Multiple samples at once
- **CSV Upload**: Bulk file processing
- Confidence scores and class probabilities
- Real-time results

### Training
- Dataset selection (Kepler/TESS/K2)
- Real-time progress tracking
- Training status updates
- Results visualization
- Model comparison

### Data Explorer
- Browse all datasets
- Sample data preview
- Feature lists
- Distribution statistics

### Model Management
- List all trained models
- Load/switch models
- View performance metrics
- Feature importance charts
- Model comparison

---

## ğŸ”§ Backend API

### Endpoints Overview

#### Health & Status
```
GET  /health          - API health check
GET  /                - Root endpoint
```

#### Predictions
```
POST /predict         - Single prediction
POST /predict/batch   - Batch predictions
POST /predict/upload  - CSV upload
```

#### Models
```
GET  /models                  - List all models
GET  /models/{name}/info      - Model details
POST /models/load/{name}      - Load model
```

#### Training
```
POST /train          - Start training
GET  /train/status   - Training progress
```

#### Features & Data
```
GET  /features/importance         - Feature importance
GET  /datasets                    - List datasets
GET  /datasets/{name}/sample      - Dataset sample
```

---

## ğŸ“ Complete File Structure

```
exoplanet/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”‚   â”œâ”€â”€ schemas.py              # Pydantic models
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ train_pipeline.py      # Complete training pipeline
â”‚   â”‚   â”œâ”€â”€ model_trainer.py       # Model training logic
â”‚   â”‚   â”œâ”€â”€ predictor.py           # Prediction service
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ data_loader.py         # Dataset loading
â”‚   â”‚   â”œâ”€â”€ preprocessing.py       # Data preprocessing
â”‚   â”‚   â”œâ”€â”€ data_exploration.py    # Data analysis
â”‚   â”‚   â”œâ”€â”€ logger.py              # Logging utilities
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ config.py              # Configuration settings
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.jsx      # Main dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ Predict.jsx        # Prediction interface
â”‚   â”‚   â”‚   â”œâ”€â”€ Training.jsx       # Training interface
â”‚   â”‚   â”‚   â”œâ”€â”€ DataExplorer.jsx   # Data exploration
â”‚   â”‚   â”‚   â””â”€â”€ Models.jsx         # Model management
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.js             # API client
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ styles/
â”‚   â”‚   â”‚   â””â”€â”€ index.css          # Global styles
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ App.jsx                # Main app component
â”‚   â”‚   â””â”€â”€ main.jsx               # Entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â””â”€â”€ postcss.config.js
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # CSV datasets
â”‚   â”‚   â”œâ”€â”€ cumulative_2025.10.04_10.17.04.csv (Kepler)
â”‚   â”‚   â”œâ”€â”€ TOI_2025.10.04_10.17.23.csv (TESS)
â”‚   â”‚   â””â”€â”€ k2pandc_2025.10.04_10.17.32.csv (K2)
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/                  # Preprocessed data
â”‚   â”‚   â””â”€â”€ preprocessor_*.pkl
â”‚   â”‚
â”‚   â””â”€â”€ models/                     # Trained models
â”‚       â”œâ”€â”€ random_forest_*.pkl
â”‚       â”œâ”€â”€ xgboost_*.pkl
â”‚       â”œâ”€â”€ lightgbm_*.pkl
â”‚       â”œâ”€â”€ neural_network_*.pkl
â”‚       â”œâ”€â”€ gradient_boosting_*.pkl
â”‚       â”œâ”€â”€ model_comparison_*.csv
â”‚       â”œâ”€â”€ training_results_*.json
â”‚       â””â”€â”€ metadata_*.json
â”‚
â”œâ”€â”€ logs/                           # Application logs
â”‚   â””â”€â”€ exoplanet_*.log
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks (optional)
â”‚
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # Full documentation
â”œâ”€â”€ QUICKSTART.md                   # Quick start guide
â”œâ”€â”€ PROJECT_OVERVIEW.md            # This file
â”œâ”€â”€ .gitignore
â”‚
â””â”€â”€ Scripts:
    â”œâ”€â”€ setup.sh                    # Setup script
    â”œâ”€â”€ run.sh                      # Run both servers
    â””â”€â”€ train.sh                    # Train models
```

---

## ğŸš€ Getting Started

### Option 1: Quick Start (Recommended)
```bash
./setup.sh    # Install dependencies
./train.sh    # Train models
./run.sh      # Start system
```

### Option 2: Manual Setup
```bash
# Backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
cd backend/models && python train_pipeline.py
cd ../api && python main.py

# Frontend (new terminal)
cd frontend
npm install
npm run dev
```

---

## ğŸ“ˆ Performance Expectations

### Training Time
- **Kepler**: 10-15 minutes
- **TESS**: 8-12 minutes
- **K2**: 5-8 minutes

### Model Accuracy (Expected)
- **Random Forest**: 90-95%
- **XGBoost**: 92-97%
- **LightGBM**: 91-96%
- **Neural Network**: 88-93%
- **Gradient Boosting**: 90-94%

### System Requirements
- **RAM**: 4GB minimum, 8GB recommended
- **CPU**: Multi-core recommended for faster training
- **Disk**: 2GB free space
- **GPU**: Optional, speeds up neural network training

---

## ğŸŒŸ Key Features Implemented

### Core Functionality âœ…
- [x] Multi-dataset support (Kepler, TESS, K2)
- [x] 5 different ML algorithms
- [x] Automated preprocessing pipeline
- [x] Feature selection and engineering
- [x] Model comparison and selection
- [x] Real-time training monitoring
- [x] Batch predictions
- [x] CSV file upload
- [x] RESTful API
- [x] Interactive web interface

### Advanced Features âœ…
- [x] Feature importance visualization
- [x] Model performance metrics
- [x] Cross-validation
- [x] Hyperparameter configuration
- [x] Data exploration tools
- [x] Confidence scores
- [x] Class probability distributions
- [x] Logging and monitoring
- [x] Error handling
- [x] CORS support

### UI/UX Features âœ…
- [x] Responsive design
- [x] Dark theme with space aesthetics
- [x] Interactive charts (Recharts)
- [x] Real-time updates
- [x] Progress indicators
- [x] Multi-page navigation
- [x] Form validation
- [x] Loading states
- [x] Error messages
- [x] Success notifications

---

## ğŸ”¬ Technical Highlights

### Backend
- **Framework**: FastAPI (modern, fast, async)
- **ML Libraries**: scikit-learn, XGBoost, LightGBM
- **Data Processing**: pandas, numpy
- **Validation**: Pydantic schemas
- **Logging**: Custom colored logger

### Frontend
- **Framework**: React 18 with Hooks
- **Build Tool**: Vite (fast HMR)
- **Styling**: Tailwind CSS
- **Charts**: Recharts
- **Icons**: Lucide React
- **Routing**: React Router v6

### Data Pipeline
- **Cleaning**: Automated duplicate/constant removal
- **Imputation**: Multiple strategies (median/mean/KNN)
- **Scaling**: StandardScaler/RobustScaler
- **Selection**: Correlation-based feature selection
- **Validation**: Stratified train/val/test split

---

## ğŸ“Š Datasets Information

### Kepler Objects of Interest (KOI)
- **Source**: Kepler Space Telescope
- **Samples**: 9,564 objects
- **Features**: 141 columns
- **Target Classes**: CONFIRMED, FALSE POSITIVE, CANDIDATE
- **Best For**: Binary classification (confirmed vs false positive)

### TESS Objects of Interest (TOI)
- **Source**: Transiting Exoplanet Survey Satellite
- **Samples**: 7,794 objects
- **Features**: Multiple transit and stellar parameters
- **Status**: Active mission, regularly updated

### K2 Planets and Candidates
- **Source**: K2 Mission (Kepler extended)
- **Samples**: 4,303 objects
- **Features**: Planet and candidate data
- **Coverage**: Multiple campaign fields

---

## ğŸ“ How It Works

### 1. Data Preprocessing
```python
Preprocessor:
  â”œâ”€â”€ Load CSV â†’ Remove duplicates
  â”œâ”€â”€ Handle missing values (median imputation)
  â”œâ”€â”€ Remove outliers (IQR clipping)
  â”œâ”€â”€ Select features (correlation > threshold)
  â”œâ”€â”€ Scale features (StandardScaler)
  â””â”€â”€ Split data (70/10/20)
```

### 2. Model Training
```python
Trainer:
  â”œâ”€â”€ Initialize 5 models
  â”œâ”€â”€ Train on training set
  â”œâ”€â”€ Validate on validation set
  â”œâ”€â”€ Evaluate on test set
  â”œâ”€â”€ Compare metrics
  â””â”€â”€ Save best model
```

### 3. Prediction
```python
Predictor:
  â”œâ”€â”€ Load trained model
  â”œâ”€â”€ Load preprocessor
  â”œâ”€â”€ Transform input data
  â”œâ”€â”€ Make prediction
  â”œâ”€â”€ Calculate confidence
  â””â”€â”€ Return probabilities
```

---

## ğŸ”® Future Enhancements

Potential improvements:
- [ ] Deep learning models (CNN, LSTM)
- [ ] Time series analysis for light curves
- [ ] Ensemble stacking
- [ ] AutoML hyperparameter tuning
- [ ] Model explainability (SHAP, LIME)
- [ ] User authentication
- [ ] Database for predictions history
- [ ] Docker containerization
- [ ] Cloud deployment
- [ ] Real-time data updates

---

## ğŸ“š References

### Datasets
- NASA Exoplanet Archive: https://exoplanetarchive.ipac.caltech.edu/
- Kepler Mission: https://www.nasa.gov/mission_pages/kepler
- TESS Mission: https://tess.mit.edu/
- K2 Mission: https://www.nasa.gov/mission_pages/kepler/main/k2-mission

### Technologies
- FastAPI: https://fastapi.tiangolo.com/
- React: https://react.dev/
- scikit-learn: https://scikit-learn.org/
- XGBoost: https://xgboost.readthedocs.io/
- LightGBM: https://lightgbm.readthedocs.io/

---

## ğŸ† Challenge Compliance

This project fulfills all NASA Space Apps Challenge requirements:

âœ… **AI/ML Model**: 5 different models trained
âœ… **NASA Datasets**: Kepler, TESS, K2 integrated
âœ… **Web Interface**: Full-featured React application
âœ… **User Interaction**: Upload, predict, train, explore
âœ… **Model Accuracy**: Displayed in UI
âœ… **Hyperparameter Control**: Configurable via code
âœ… **Data Upload**: CSV upload supported
âœ… **Manual Entry**: Single prediction form
âœ… **Statistics**: Comprehensive metrics dashboard
âœ… **Open Source**: All code available

---

## ğŸ’¡ Innovation Points

1. **Multi-Model Ensemble**: Train 5 models simultaneously
2. **Real-Time Monitoring**: Watch training progress live
3. **Complete Pipeline**: From raw data to predictions
4. **Professional UI**: Production-ready interface
5. **Comprehensive API**: 15+ endpoints
6. **Feature Engineering**: Automated selection
7. **Batch Processing**: Handle large datasets
8. **Model Comparison**: Side-by-side metrics
9. **Visualization**: Interactive charts
10. **Developer Tools**: Scripts for easy setup

---

**Built with passion for space exploration and AI! ğŸš€ğŸŒŒ**

*For NASA Space Apps Challenge 2025*
